"""Comprehensive monitoring and metrics collection system.

This module provides performance tracking, resource monitoring, and alert thresholds
for the Music Genre Updater system. Implements MetricsCollector class with comprehensive
monitoring capabilities.
"""

from __future__ import annotations

import asyncio
import contextlib
import logging
import time

try:
    import psutil  # type: ignore
    _psutil_module = psutil
    psutil_available = True
except ImportError:
    _psutil_module = None
    psutil_available = False
    psutil = None

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import UTC, datetime
from enum import Enum
from typing import TYPE_CHECKING, Any, Self, TypeVar

if TYPE_CHECKING:
    import types
    from collections.abc import Callable

logger = logging.getLogger(__name__)

T = TypeVar("T")

# Constants
FLOAT_COMPARISON_TOLERANCE = 0.001  # Tolerance for floating point comparisons
MIN_HISTORY_LENGTH = 2  # Minimum number of data points required for rate calculation


def _get_psutil() -> Any:
    """Get psutil module if available."""
    if not psutil_available or _psutil_module is None:
        error_msg = "psutil is not available"
        raise RuntimeError(error_msg)
    return _psutil_module


def _create_empty_tags() -> dict[str, str]:
    """Create empty tags dictionary with proper typing."""
    return {}


def _create_empty_metadata() -> dict[str, Any]:
    """Create empty metadata dictionary with proper typing."""
    return {}


class AlertLevel(Enum):
    """Alert severity levels."""

    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class ResourceType(Enum):
    """System resource types."""

    CPU = "cpu"
    MEMORY = "memory"
    DISK = "disk"
    NETWORK = "network"


@dataclass
class PerformanceMetric:
    """Performance metric data point."""

    name: str
    value: float
    timestamp: datetime
    unit: str = ""
    tags: dict[str, str] = field(default_factory=_create_empty_tags)


@dataclass
class ResourceMetric:
    """System resource metric."""

    resource_type: ResourceType
    usage_percent: float
    available: int
    total: int
    timestamp: datetime
    metadata: dict[str, Any] = field(default_factory=_create_empty_metadata)


@dataclass
class Alert:
    """System alert."""

    level: AlertLevel
    message: str
    timestamp: datetime
    source: str
    metric_name: str
    value: float
    threshold: float
    metadata: dict[str, Any] = field(default_factory=_create_empty_metadata)


class AlertRule(ABC):
    """Abstract base class for alert rules."""

    def __init__(self, name: str, threshold: float, level: AlertLevel) -> None:
        """Initialize alert rule with name, threshold, and severity level.

        Args:
            name: Human-readable name for this alert rule
            threshold: Numeric threshold value for triggering alerts
            level: Severity level of alerts generated by this rule

        """
        self.name = name
        self.threshold = threshold
        self.level = level

    @abstractmethod
    def evaluate(self, metric: PerformanceMetric | ResourceMetric) -> Alert | None:
        """Evaluate metric against rule."""


class ThresholdRule(AlertRule):
    """Simple threshold-based alert rule."""

    def __init__(
        self,
        name: str,
        threshold: float,
        level: AlertLevel,
        operator: str = "greater",
    ) -> None:
        """Initialize threshold-based alert rule.

        Args:
            name: Human-readable name for this alert rule
            threshold: Numeric threshold value for triggering alerts
            level: Severity level of alerts generated by this rule
            operator: Comparison operator ("greater", "less", "equal")

        """
        super().__init__(name, threshold, level)
        self.operator = operator

    def evaluate(self, metric: PerformanceMetric | ResourceMetric) -> Alert | None:
        """Evaluate threshold rule."""
        value = metric.value if isinstance(metric, PerformanceMetric) else metric.usage_percent

        should_alert = False
        if self.operator == "greater":
            should_alert = value > self.threshold
        elif self.operator == "less":
            should_alert = value < self.threshold
        elif self.operator == "equal":
            should_alert = abs(value - self.threshold) < FLOAT_COMPARISON_TOLERANCE

        if should_alert:
            return Alert(
                level=self.level,
                message=f"{self.name}: {value} {self.operator} {self.threshold}",
                timestamp=datetime.now(UTC),
                source=self.__class__.__name__,
                metric_name=(metric.name if isinstance(metric, PerformanceMetric) else metric.resource_type.value),
                value=value,
                threshold=self.threshold,
            )

        return None


class RateOfChangeRule(AlertRule):
    """Alert rule based on rate of change."""

    def __init__(
        self,
        name: str,
        threshold: float,
        level: AlertLevel,
        window_size: int = 10,
    ) -> None:
        """Initialize rate-of-change alert rule.

        Args:
            name: Human-readable name for this alert rule
            threshold: Rate of change threshold for triggering alerts (units/second)
            level: Severity level of alerts generated by this rule
            window_size: Number of historical data points to maintain for rate calculation

        """
        super().__init__(name, threshold, level)
        self.window_size = window_size
        self.history: list[tuple[float, datetime]] = []

    def evaluate(self, metric: PerformanceMetric | ResourceMetric) -> Alert | None:
        """Evaluate rate of change rule."""
        now = datetime.now(UTC)
        value = metric.value if isinstance(metric, PerformanceMetric) else metric.usage_percent

        # Add current value to history
        self.history.append((value, now))

        # Keep only recent history
        if len(self.history) > self.window_size:
            self.history.pop(0)

        # Need at least minimum number of points for rate calculation
        if len(self.history) < MIN_HISTORY_LENGTH:
            return None

        # Calculate the rate of change
        oldest_value, oldest_time = self.history[0]
        time_diff = (now - oldest_time).total_seconds()

        if time_diff == 0:
            return None

        rate = (value - oldest_value) / time_diff

        if abs(rate) > self.threshold:
            return Alert(
                level=self.level,
                message=f"{self.name}: Rate of change {rate:.2f}/s exceeds {self.threshold}/s",
                timestamp=now,
                source=self.__class__.__name__,
                metric_name=(metric.name if isinstance(metric, PerformanceMetric) else metric.resource_type.value),
                value=rate,
                threshold=self.threshold,
                metadata={"window_size": self.window_size},
            )

        return None


class PerformanceTracker:
    """Tracks application performance metrics."""

    def __init__(self) -> None:
        """Initialize performance tracker with empty metrics storage."""
        self.metrics: list[PerformanceMetric] = []
        self.operation_timers: dict[str, float] = {}
        self.counters: dict[str, int] = {}

    def start_operation(self, operation_name: str) -> None:
        """Start timing an operation."""
        self.operation_timers[operation_name] = time.time()

    def end_operation(self, operation_name: str, tags: dict[str, str] | None = None) -> float:
        """End timing an operation and record metric."""
        if operation_name not in self.operation_timers:
            logger.warning("Operation %s was not started", operation_name)
            return 0.0

        duration = time.time() - self.operation_timers[operation_name]
        del self.operation_timers[operation_name]

        metric = PerformanceMetric(
            name=f"operation_duration_{operation_name}",
            value=duration,
            timestamp=datetime.now(UTC),
            unit="seconds",
            tags=tags or {},
        )

        self.metrics.append(metric)
        return duration

    def record_counter(self, counter_name: str, increment: int = 1, tags: dict[str, str] | None = None) -> None:
        """Record a counter increment."""
        self.counters[counter_name] = self.counters.get(counter_name, 0) + increment

        metric = PerformanceMetric(
            name=counter_name,
            value=self.counters[counter_name],
            timestamp=datetime.now(UTC),
            unit="count",
            tags=tags or {},
        )

        self.metrics.append(metric)

    def record_gauge(
        self,
        gauge_name: str,
        value: float,
        unit: str = "",
        tags: dict[str, str] | None = None,
    ) -> None:
        """Record a gauge value."""
        metric = PerformanceMetric(
            name=gauge_name,
            value=value,
            timestamp=datetime.now(UTC),
            unit=unit,
            tags=tags or {},
        )

        self.metrics.append(metric)

    def get_metrics(self, since: datetime | None = None) -> list[PerformanceMetric]:
        """Get performance metrics since a specific time."""
        if since is None:
            return self.metrics.copy()

        return [m for m in self.metrics if m.timestamp >= since]

    def clear_metrics(self) -> None:
        """Clear stored metrics."""
        self.metrics.clear()


class ResourceMonitor:
    """Monitors system resources."""

    def __init__(self) -> None:
        """Initialize resource monitor with empty metrics storage."""
        self.metrics: list[ResourceMetric] = []

    def collect_cpu_metrics(self) -> ResourceMetric:
        """Collect CPU usage metrics."""
        if not psutil_available:
            return ResourceMetric(
                resource_type=ResourceType.CPU,
                usage_percent=0.0,
                available=100,
                total=100,
                timestamp=datetime.now(UTC),
                metadata={"cpu_count": 1, "cpu_freq": {}, "psutil_unavailable": True},
            )

        psutil_module = _get_psutil()
        cpu_percent = psutil_module.cpu_percent(interval=1)
        cpu_count = psutil_module.cpu_count()

        metric = ResourceMetric(
            resource_type=ResourceType.CPU,
            usage_percent=cpu_percent,
            available=int((100 - cpu_percent) * cpu_count),
            total=cpu_count * 100,
            timestamp=datetime.now(UTC),
            metadata={
                "cpu_count": cpu_count,
                "cpu_freq": self._get_cpu_freq_dict(psutil_module) if psutil_module else {},
            },
        )

        self.metrics.append(metric)
        return metric

    @staticmethod
    def _get_cpu_freq_dict(psutil_module: Any) -> dict[str, float ]:
        """Get CPU frequency information as dictionary without using protected _asdict method."""
        cpu_freq = psutil_module.cpu_freq()
        if cpu_freq is None:
            return {}

        # Create dictionary manually from namedtuple attributes
        return {
            "current": float(cpu_freq.current) if hasattr(cpu_freq, "current") else 0.0,
            "min": float(cpu_freq.min) if hasattr(cpu_freq, "min") else 0.0,
            "max": float(cpu_freq.max) if hasattr(cpu_freq, "max") else 0.0,
        }

    def collect_memory_metrics(self) -> ResourceMetric:
        """Collect memory usage metrics."""
        if not psutil_available:
            return ResourceMetric(
                resource_type=ResourceType.MEMORY,
                usage_percent=0.0,
                available=1024 * 1024 * 1024,  # 1GB
                total=1024 * 1024 * 1024,
                timestamp=datetime.now(UTC),
                metadata={
                    "used": 0,
                    "cached": 0,
                    "buffers": 0,
                    "psutil_unavailable": True,
                },
            )

        psutil_module = _get_psutil()
        memory = psutil_module.virtual_memory()

        metric = ResourceMetric(
            resource_type=ResourceType.MEMORY,
            usage_percent=memory.percent,
            available=memory.available,
            total=memory.total,
            timestamp=datetime.now(UTC),
            metadata={
                "used": memory.used,
                "cached": getattr(memory, "cached", 0),
                "buffers": getattr(memory, "buffers", 0),
            },
        )

        self.metrics.append(metric)
        return metric

    def collect_disk_metrics(self, path: str = "/") -> ResourceMetric:
        """Collect disk usage metrics."""
        if not psutil_available:
            return ResourceMetric(
                resource_type=ResourceType.DISK,
                usage_percent=0.0,
                available=10 * 1024 * 1024 * 1024,  # 10GB
                total=10 * 1024 * 1024 * 1024,
                timestamp=datetime.now(UTC),
                metadata={"path": path, "used": 0, "psutil_unavailable": True},
            )

        psutil_module = _get_psutil()
        disk = psutil_module.disk_usage(path)

        usage_percent = (disk.used / disk.total) * 100

        metric = ResourceMetric(
            resource_type=ResourceType.DISK,
            usage_percent=usage_percent,
            available=disk.free,
            total=disk.total,
            timestamp=datetime.now(UTC),
            metadata={
                "path": path,
                "used": disk.used,
            },
        )

        self.metrics.append(metric)
        return metric

    def collect_all_metrics(self, disk_path: str = "/") -> list[ResourceMetric]:
        """Collect all resource metrics."""
        return [
            self.collect_cpu_metrics(),
            self.collect_memory_metrics(),
            self.collect_disk_metrics(disk_path),
        ]

    def get_metrics(
        self, resource_type: ResourceType | None = None, since: datetime | None = None
    ) -> list[ResourceMetric]:
        """Get resource metrics filtered by type and time."""
        filtered_metrics = self.metrics

        if resource_type:
            filtered_metrics = [m for m in filtered_metrics if m.resource_type == resource_type]

        if since:
            filtered_metrics = [m for m in filtered_metrics if m.timestamp >= since]

        return filtered_metrics

    def clear_metrics(self) -> None:
        """Clear stored metrics."""
        self.metrics.clear()


class AlertManager:
    """Manages alerts and alert rules."""

    def __init__(self) -> None:
        """Initialize alert manager with empty rules, alerts, and handlers."""
        self.rules: list[AlertRule] = []
        self.alerts: list[Alert] = []
        self.handlers: list[Callable[[Alert], None]] = []

    def add_rule(self, rule: AlertRule) -> None:
        """Add an alert rule."""
        self.rules.append(rule)

    def add_handler(self, handler: Callable[[Alert], None]) -> None:
        """Add an alert handler."""
        self.handlers.append(handler)

    def evaluate_metrics(self, metrics: list[PerformanceMetric | ResourceMetric]) -> list[Alert]:
        """Evaluate metrics against all rules."""
        new_alerts: list[Alert] = []

        for metric in metrics:
            for rule in self.rules:
                if alert := rule.evaluate(metric):
                    new_alerts.append(alert)
                    self.alerts.append(alert)

                    # Notify handlers
                    for handler in self.handlers:
                        try:
                            handler(alert)
                        except (TypeError, ValueError, RuntimeError):
                            logger.exception("Alert handler failed")

        return new_alerts

    def get_alerts(self, level: AlertLevel | None = None, since: datetime | None = None) -> list[Alert]:
        """Get alerts filtered by level and time."""
        filtered_alerts = self.alerts

        if level:
            filtered_alerts = [a for a in filtered_alerts if a.level == level]

        if since:
            filtered_alerts = [a for a in filtered_alerts if a.timestamp >= since]

        return filtered_alerts

    def clear_alerts(self) -> None:
        """Clear stored alerts."""
        self.alerts.clear()


class MetricsCollector:
    """Main metrics collection and monitoring system."""

    def __init__(self) -> None:
        """Initialize metrics collector with trackers, monitors, and default configuration."""
        self.performance_tracker = PerformanceTracker()
        self.resource_monitor = ResourceMonitor()
        self.alert_manager = AlertManager()
        self.running = False
        self.collection_task: asyncio.Task[None] | None = None
        self.collection_interval = 30.0  # seconds

        # Set up default alert rules
        self._setup_default_alerts()

    def _setup_default_alerts(self) -> None:
        """Set up default alert rules for CPU, memory, and disk monitoring."""
        # CPU alerts
        self.alert_manager.add_rule(ThresholdRule("High CPU Usage", 80.0, AlertLevel.WARNING))
        self.alert_manager.add_rule(ThresholdRule("Critical CPU Usage", 95.0, AlertLevel.CRITICAL))

        # Memory alerts
        self.alert_manager.add_rule(ThresholdRule("High Memory Usage", 85.0, AlertLevel.WARNING))
        self.alert_manager.add_rule(ThresholdRule("Critical Memory Usage", 95.0, AlertLevel.CRITICAL))

        # Disk alerts
        self.alert_manager.add_rule(ThresholdRule("High Disk Usage", 90.0, AlertLevel.WARNING))

    def start_monitoring(self, interval: float = 30.0) -> None:
        """Start continuous monitoring."""
        self.collection_interval = interval
        self.running = True

        if self.collection_task is None or self.collection_task.done():
            self.collection_task = asyncio.create_task(self._collection_loop())

    async def stop_monitoring(self) -> None:
        """Stop continuous monitoring."""
        self.running = False

        if self.collection_task and not self.collection_task.done():
            self.collection_task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await self.collection_task

    async def _collection_loop(self) -> None:
        """Run the main metrics collection loop continuously."""
        while self.running:
            try:
                # Collect resource metrics
                resource_metrics = self.resource_monitor.collect_all_metrics()

                # Get recent performance metrics
                recent_performance = self.performance_tracker.get_metrics(
                    since=datetime.now(UTC).replace(second=0, microsecond=0)
                )

                # Evaluate alerts
                all_metrics = resource_metrics + recent_performance
                self.alert_manager.evaluate_metrics(all_metrics)

                await asyncio.sleep(self.collection_interval)

            except asyncio.CancelledError:
                logger.info("Metrics collection cancelled")
                raise  # Re-raise CancelledError for proper cancellation
            except (OSError, RuntimeError, ValueError):
                logger.exception("Metrics collection error")
                await asyncio.sleep(5)  # Brief pause before retry

    def record_operation(self, operation_name: str) -> OperationContext:
        """Context manager for recording operation duration."""
        return OperationContext(self.performance_tracker, operation_name)

    def record_counter(self, counter_name: str, increment: int = 1, tags: dict[str, str] | None = None) -> None:
        """Record counter increment."""
        self.performance_tracker.record_counter(counter_name, increment, tags)

    def record_gauge(
        self,
        gauge_name: str,
        value: float,
        unit: str = "",
        tags: dict[str, str] | None = None,
    ) -> None:
        """Record gauge value."""
        self.performance_tracker.record_gauge(gauge_name, value, unit, tags)

    def add_alert_rule(self, rule: AlertRule) -> None:
        """Add custom alert rule."""
        self.alert_manager.add_rule(rule)

    def add_alert_handler(self, handler: Callable[[Alert], None]) -> None:
        """Add alert handler."""
        self.alert_manager.add_handler(handler)

    def get_summary(self) -> dict[str, Any]:
        """Get comprehensive monitoring summary."""
        now = datetime.now(UTC)
        hour_ago = now.replace(minute=0, second=0, microsecond=0)

        recent_alerts = self.alert_manager.get_alerts(since=hour_ago)
        recent_performance = self.performance_tracker.get_metrics(since=hour_ago)
        recent_resources = self.resource_monitor.get_metrics(since=hour_ago)

        return {
            "timestamp": now.isoformat(),
            "monitoring_status": "running" if self.running else "stopped",
            "alerts": {
                "total": len(recent_alerts),
                "by_level": {level.value: len([a for a in recent_alerts if a.level == level]) for level in AlertLevel},
                "recent": [
                    {
                        "level": alert.level.value,
                        "message": alert.message,
                        "timestamp": alert.timestamp.isoformat(),
                        "source": alert.source,
                    }
                    for alert in recent_alerts[-5:]  # Last 5 alerts
                ],
            },
            "performance": {
                "metrics_count": len(recent_performance),
                "operations": len({m.name for m in recent_performance if "operation_duration" in m.name}),
            },
            "resources": {
                "metrics_count": len(recent_resources),
                "latest": {
                    metric.resource_type.value: {
                        "usage_percent": metric.usage_percent,
                        "available": metric.available,
                        "total": metric.total,
                    }
                    for metric in recent_resources[-3:]  # Latest CPU, Memory, Disk
                },
            },
        }


class OperationContext:
    """Context manager for tracking operation performance."""

    def __init__(
        self,
        tracker: PerformanceTracker,
        operation_name: str,
        tags: dict[str, str] | None = None,
    ) -> None:
        """Initialize operation context for performance tracking.

        Args:
            tracker: Performance tracker instance to record metrics to
            operation_name: Name of the operation being tracked
            tags: Optional metadata tags to associate with the operation

        """
        self.tracker = tracker
        self.operation_name = operation_name
        self.tags = tags

    def __enter__(self) -> Self:
        """Enter the operation context and start timing."""
        self.tracker.start_operation(self.operation_name)
        return self

    def __exit__(
        self,
        exc_type: type[BaseException] | None,
        exc_val: BaseException | None,
        exc_tb: types.TracebackType | None,
    ) -> None:
        """Exit the operation context, record duration and success/error counters."""
        self.tracker.end_operation(self.operation_name, self.tags)
        if exc_type:
            self.tracker.record_counter(f"operation_errors_{self.operation_name}", tags=self.tags)
        else:
            self.tracker.record_counter(f"operation_success_{self.operation_name}", tags=self.tags)


def _create_metrics_collector_getter() -> Callable[[], MetricsCollector]:
    """Create a metrics collector getter function with closure-based singleton."""
    instance: MetricsCollector | None = None

    def _get_collector() -> MetricsCollector:
        """Get or create the singleton MetricsCollector instance."""
        nonlocal instance
        if instance is None:
            instance = MetricsCollector()
        return instance

    return _get_collector


# Create the actual function that external code will use
get_metrics_collector = _create_metrics_collector_getter()


def log_alert_handler(alert: Alert) -> None:
    """Log alerts using the default logging handler."""
    level_map = {
        AlertLevel.INFO: logging.INFO,
        AlertLevel.WARNING: logging.WARNING,
        AlertLevel.ERROR: logging.ERROR,
        AlertLevel.CRITICAL: logging.CRITICAL,
    }

    logger.log(
        level_map[alert.level],
        "ALERT [%s]: %s",
        alert.level.value.upper(),
        alert.message,
    )


# Setup default alert handler
get_metrics_collector().add_alert_handler(log_alert_handler)
